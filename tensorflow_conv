# -*- coding: utf-8 -*-
"""
Created on Sat Oct  6 11:05:44 2018

@author: Administrator
"""

import time
import tensorflow as tf
import numpy as np
import matplotlib as pls
from tensorflow.examples.tutorials.mnist import input_data


mnist=input_data.read_data_sets("MNIST_data",one_hot=True)
batch_size=100
n_batch=mnist.train.num_examples//batch_size

'''
权重值赋值为高斯分布，标准差为0.1
'''
def weight_variable(shape):
    initial=tf.truncated_normal(shape,stddev=0.1)
    return tf.Variable(initial)
'''
偏置值常量为0.1
'''
def bias_variable(shape):
    initial=tf.constant(0.1,shape=shape)
    return tf.Variable(initial)

'''
卷积层tf.nn.conv2d()这个函数的功能如下：
X输入shape[batch,in-height,in-weith,in-channels]
w过滤器核filter(kernel)shape[filter-height,filter-width,in-channels,out-channels]
strides步长　strides[0]=strides[1]=1,必须要填写０，３，大部分情况下，横向和竖向都是同样的步长
padding是否补０，如果要输出像素一样的大小，要在图周围补０用‘SAME’其它用VALID
'''
def conv2d(x,w):
    return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding='SAME')


'''
池化层和卷积层一样的设置
ksize=[1,height,width,1]这个的设置和Ｘ输入是一样的X输入shape[batch,in-height,in-weith,in-channels]
这里函数设置了2X2的池化过滤器大小
strides = [1, stride, stride, 1] 0,3是固定参数，１，２是横和和竖向
'''
def maxpool2X2(x):
    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')






'''
x-image 改变Ｘ的shape为４Ｄ的向量[batch,height,width,channels]]
'''


with tf.name_scope('input'):
    x=tf.placeholder(tf.float32,[None,784],name='x-input')
    y=tf.placeholder(tf.float32,[None,10],name='y-input')
    
x_image=tf.reshape(x,[-1,28,28,1])    
##############################layer1######################################
'''
第一个卷积神经网络,w_conv1是滤波器，ＣＯＮＶ步长为１

'''
with tf.name_scope('conv-layer_1'):
    
    w_conv1=weight_variable([5,5,1,32])
    b_conv1=bias_variable([32])
    h_conv1=tf.nn.relu(conv2d(x_image,w_conv1)+b_conv1)

'''
池化ＰＯＯＬ　ＰＯＯＬ步长为２
'''
with tf.name_scope('pool_1'):
    h_pool1=maxpool2X2(h_conv1)

#############################layer2#######################################
with tf.name_scope('conv-layer_2'):
    w_conv2=weight_variable([5,5,32,64])
    b_conv2=bias_variable([64])
    h_conv2=tf.nn.relu(conv2d(h_pool1,w_conv2)+b_conv2)

'''
池化ＰＯＯＬ　ＰＯＯＬ步长为２　计算公式为:(n-2p-f)/s+1 n是输入的大小，Ｆ是滤波器大小，Ｐ是Ｐadding
'''
with tf.name_scope('pool_2'):
    h_pool2=maxpool2X2(h_conv2)


############################full connect1##################################
with tf.name_scope('full_connect1'):
    w_fc1=weight_variable([7*7*64,1024])
    b_fcl=bias_variable([1024])
    h_pool2_flat=tf.reshape(h_pool2,[-1,7*7*64])
    h_fcl=tf.nn.relu(tf.matmul(h_pool2_flat,w_fc1)+b_fcl)
    
with tf.name_scope('keep-prob'): 
    keep_prob=tf.placeholder(tf.float32)
    h_fc1_drop=tf.nn.dropout(h_fcl,keep_prob)

############################full connect2##################################
with tf.name_scope('full_connect2'):
    w_fc2=weight_variable([1024,10])
    b_fc2=bias_variable([10])
    
###########计算输出#####################

prediction=tf.nn.softmax(tf.matmul(h_fc1_drop,w_fc2)+b_fc2)

###########计算Ｇ()输出交插商#####################
cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))

###########用Adamoptimizer进行优化#####################
train_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

#######求得预测值和输出值中的最大值，如果相等＝１，不相等＝０，最后得到布尔值
correct_prediction=tf.equal(tf.arg_max(prediction,1),(tf.arg_max(y,1)))
#######布尔值转换成float32,然后求平均值，
accurcy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))

inital=tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(inital)
    for epoch in range(18):#总的运行跌代次数
        for batch in range(n_batch):#每次总数/１００张图片
            batch_xs,batch_ys=mnist.train.next_batch(batch_size)
            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})
            
        acc=sess.run(accurcy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})
        print('第',epoch+1,'次精度＝',acc*100)                       


































 
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
